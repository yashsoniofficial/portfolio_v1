A reinforcement learning-based framework for trajectory planning of a UR5e robotic arm in dynamic and constrained environments. Developed in CoppeliaSim, the system uses Proximal Policy Optimization (PPO), Constrained Markov Decision Processes (CMDP), and Fuzzy Movement Primitives (FMP) to train the robot to reach randomly placed goals while avoiding dynamic obstacles. The hybrid control system combines learned behavior with real-time reactive adjustments. The agent learns smooth, collision-free motion closely aligned with inverse kinematics predictions, making it ideal for future multi-arm robot coordination in complex industrial or collaborative environments.